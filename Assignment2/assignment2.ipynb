{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kw03_k_rLQ0U"
   },
   "source": [
    "First of all, I have imported all libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vHvmTKEdINdX"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import svm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.fixes import loguniform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-SaPFPKLfC8"
   },
   "source": [
    "A)In 'mnist' I have fetched the data that we need to process in ML with 'svm'\n",
    "algorithm for trainning and testing the data. As we were asked in the problem, I reduced the data to 6000 for training and 1000 for testing\n",
    "and I used 'svm' with linear kernel and default parameter values, I have scored the accuracity in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhCUgTWkH2PV",
    "outputId": "3c3e7318-6a48-4f61-a6f4-81f1dce76bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.8\n"
     ]
    }
   ],
   "source": [
    "mnist =  fetch_openml('mnist_784')\n",
    "X = mnist.data\n",
    "Y = mnist.target\n",
    "X = X/255.0*2 - 1\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size= 6000, test_size=1000)\n",
    "svc = svm.SVC(kernel ='linear').fit(X_train, Y_train)\n",
    "print(svc.score(X_test, Y_test)*100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-F0SyllMInX"
   },
   "source": [
    "B)I have used 'svm' with RBF kernel and default parameter values and I have scored the accuracity for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYswdd-uH24T",
    "outputId": "d451eb47-b165-4ed2-ad05-c21a178fb15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.8\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(kernel ='rbf').fit(X_train, Y_train)\n",
    "print(svc.score(X_test, Y_test)*100) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjszc0PSH3Ip"
   },
   "source": [
    "C)\n",
    "Hyperparameters are commonly chosen by human based on some intuition or hit and trial before the actual training begins. These parameters exhibits their importance by improving performance of the model such as its complexity or its learning rate. Models can have many hyper-parameters and finding the best combination of parameters can be treated as a search problem.\n",
    "\n",
    "SVM also has some hyper-parameters (like what C or gamma values to use) and finding optimal hyper-parameter is a very hard task to solve. But it can be found by just trying all combinations and see what parameters work best. The main idea behind it is to create a grid of hyper-parameters and just try all of their combinations (hence, this method is called Gridsearch, Scikit-learn has this functionality built-in with GridSearchCV.\n",
    "\n",
    "GridSearchCV takes a dictionary that describes the parameters that could be tried on a model to train it. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.\n",
    "\n",
    "Based on above writing, I have clarified C and gamma parameters ranges for svm with RBF kernel using gridsearch and fit the training data to find the optimal C and Gamma.\n",
    "\n",
    "E)Here under I have also measured the total time clocking for gridsearch running time algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sz-dqAwGH3Yy",
    "outputId": "23fe7530-48ca-49f5-c8d2-4e644afab8af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "C_range = np.arange( 1, 100+1, 1 ).tolist()\n",
    "#C_range = 10. ** np.arange(-3, 8)\n",
    "#gamma_range = 10. ** np.arange(-5, 4)\n",
    "gamma_range = np.arange( 0.0, 10.0+0.0, 0.1 ).tolist()\n",
    "\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "SVC = svm.SVC(kernel ='rbf')\n",
    "grid = GridSearchCV(SVC, param_grid=param_grid, cv=StratifiedKFold(n_splits=5))\n",
    "start = time.clock()  \n",
    "grid.fit(X_train, Y_train)\n",
    "end = time.clock()  \n",
    "print(\"The best classifier is: \", grid.best_estimator_)\n",
    "print(\"Processor time (in seconds):\", end)  \n",
    "print(\"Time elapsed during the calculation:\", end - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YnG0kXaH3lb"
   },
   "source": [
    "I have clarified C and gamma parameters ranges for svm with RBF kernel using randomsizedsearch and fit the training data to find the optimal C and Gamma.\n",
    "\n",
    "E)Here under I have also measured the total time clocking for randomsizedsearch running time algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpAGWxCIH3y5"
   },
   "outputs": [],
   "source": [
    "C_range = loguniform(1e0, 1e3),\n",
    "gamma_range = loguniform(1e-4, 1e-3)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "grid2 = RandomizedSearchCV(SVC, param_distributions=param_grid, cv=StratifiedKFold(n_splits=5), n_iter=20)\n",
    "start = time.clock()  \n",
    "grid2.fit(X_train, Y_train)\n",
    "end = time.clock()  \n",
    "\n",
    "print(\"The best classifier is: \", grid2.best_estimator_)\n",
    "print(\"Processor time (in seconds):\", end)  \n",
    "print(\"Time elapsed during the calculation:\", end - start)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9cMo0pNQIU0"
   },
   "source": [
    "F)At last, I have train my models with founded optimal parameters by grid search or by random search \n",
    "unfortunetly the time for calculating these number of data was too much so I had to change the train into 600 and test to 100, when I changed it to upper size, the C and Gamma have been changed and I think if we choose random_state = 111 we will get more accuracity. \n",
    "The accuracity on grid and random was nearly equal\n",
    "but the time on grid was much bigger than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4A4vZL51ESfL"
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel ='rbf', C=1.0, gamma=0.01).fit(X_train, Y_train)\n",
    "print(svc.score(X_test, Y_test)) \n",
    "\n",
    "svc = svm.SVC(kernel ='rbf', C=1.0, gamma=0.01).fit(X_train, Y_train)\n",
    "print(svc.score(X_test, Y_test)) \n",
    "\n",
    "#optimal\n",
    "svc = svm.SVC(kernel ='rbf', C=1.0, gamma=0.01).fit(X_train, Y_train)\n",
    "print(svc.score(X_test, Y_test)) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
